{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biofilm Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this Notebook\n",
    "\n",
    "- Data Augmentation\n",
    "- PCA Dimension Reduction\n",
    "- SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional python packages\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from time import time\n",
    "import logging\n",
    "import os, urllib, io, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "# from ggplot import *\n",
    "# import umap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from image_processing_functions import * # Our functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading day 4 and day 5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size = 150\n",
    "path = 'final_dataset/'\n",
    "\n",
    "all_images=[]\n",
    "all_names=[]\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for name in files:\n",
    "        if int(name.split('_')[1]) > 3:\n",
    "            mypath = os.path.join(root,name)\n",
    "            img = Image.open(mypath, mode = 'r')\n",
    "            img = img.resize((size, size))\n",
    "            arr = np.array(img).astype('uint8')\n",
    "            all_images.append(arr)\n",
    "            img.close()\n",
    "            all_names.append(name.split('.')[0])\n",
    "            \n",
    "dic_features = {'biofilm' : all_names}\n",
    "labels = np.array([name.split('_')[0] for name in all_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biofilm labels are invariant by rotation and transposition. It is therefore easily multiply the size of our training dataset by 8: 4 rotations * 2 transpose. We therefore use this method to improve our SVM. We  fit the PCA on the non-expanded train set for computation efficiency. With this method, our f1 score on the train set jumps from 83% to 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x.flatten() for x in all_images]\n",
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the train and test sets before augmenting. We only augment the training data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "# Augment training set\n",
    "X_expanded = []\n",
    "y_expanded = []\n",
    "rotation = [0, 90, 180, 270]\n",
    "for i, x in enumerate(X_train):\n",
    "    for angle in rotation:\n",
    "        img = Image.fromarray(x)\n",
    "        img_rotate = img.rotate(angle)\n",
    "        img_transpose = img_rotate.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        arr_rotate = np.array(img_rotate).astype('uint8')\n",
    "        arr_transpose = np.array(img_transpose).astype('uint8')\n",
    "        X_expanded.append(arr_rotate)\n",
    "        X_expanded.append(arr_transpose)\n",
    "        y_expanded.append(y_train[i])\n",
    "        y_expanded.append(y_train[i])\n",
    "\n",
    "# flatten\n",
    "X_train = np.array([x.flatten() for x in X_expanded])\n",
    "X_test = np.array([x.flatten() for x in X_test])\n",
    "\n",
    "# shuffle \n",
    "indices = np.arange(len(X_train))\n",
    "np.random.shuffle(indices)\n",
    "X_train = X_train[indices]\n",
    "y_train = np.array(y_expanded)[indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing PCA\n",
    "\n",
    "We choose to use 50 Principle Components, as larger values increase procesing time significantly with little improvement on classification accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a PCA \n",
    "n_components = 50\n",
    "\n",
    "print(\"Extracting the top %d eigenvectors from %d biofilms\"\n",
    "      % (n_components, X_train.shape[0]))\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "\n",
    "print(\"Projecting the input data on the eigen orthonormal basis\")\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 50 eigenvectors from 3072 biofilms\n",
      "done in 5.441s\n",
      "Projecting the input data on the eigen orthonormal basis\n",
      "done in 0.982s\n",
      "Fitting the classifier to the training set\n",
      "done in 143.376s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=50000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'),\n",
    "                   param_grid, cv=5)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting mutant type based on the test set\n",
      "done in 0.079s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       4133       0.79      0.94      0.86        16\n",
      "   cco1cco2       1.00      0.95      0.97        19\n",
      "       dipA       0.78      1.00      0.88        14\n",
      "       pas9       0.87      0.87      0.87        23\n",
      "        phz       1.00      0.94      0.97        18\n",
      "       rmcA       1.00      0.93      0.97        15\n",
      "         wt       0.95      0.78      0.86        23\n",
      "\n",
      "avg / total       0.92      0.91      0.91       128\n",
      "\n",
      "[[15  0  0  1  0  0  0]\n",
      " [ 1 18  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  0  0]\n",
      " [ 1  0  1 20  0  0  1]\n",
      " [ 0  0  1  0 17  0  0]\n",
      " [ 1  0  0  0  0 14  0]\n",
      " [ 1  0  2  2  0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting mutant type based on the test set\")\n",
    "t0 = time()\n",
    "\n",
    "X_test_pca = pca.transform(X_test)\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(classification_report(y_test, y_pred))#, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
